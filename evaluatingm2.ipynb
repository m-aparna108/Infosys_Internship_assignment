{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation of Whisper-Medium ASR Model\n",
        "\n",
        "This notebook evaluates the **Whisper-medium** automatic speech recognition (ASR) model on the **GSL English Podcast Dataset** from **Hugging Face**. The objective is to analyze how accurately the model transcribes short English speech clips.\n",
        "\n",
        "The audio samples are preprocessed and passed through the pretrained **Whisper-medium** model to generate transcriptions. Model performance is measured using standard ASR evaluation metrics:\n",
        "\n",
        "- **Word Error Rate (WER)**\n",
        "- **Character Error Rate (CER)**\n",
        "\n"
      ],
      "metadata": {
        "id": "DyHDPYd6gWeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torchaudio librosa soundfile --quiet"
      ],
      "metadata": {
        "id": "M_rt98aUgYHf"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchcodec --quiet"
      ],
      "metadata": {
        "id": "Dq_aGXeTiUWz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
        "import torch\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "whisper_processor = WhisperProcessor.from_pretrained(\"openai/whisper-medium\")\n",
        "whisper_model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-medium\").to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOcA-d9NhnX3",
        "outputId": "8151dda7-b0a5-4480-99c8-e660519046a2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jiwer --quiet"
      ],
      "metadata": {
        "id": "rt7XoS3TiI3P"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, Audio\n",
        "import librosa\n",
        "import numpy as np\n",
        "from jiwer import wer, cer\n",
        "\n",
        "# Load dataset (decoded audio)\n",
        "dataset = load_dataset(\"vietnhat/gsl-english-podcast-dataset\")\n",
        "dataset = dataset.cast_column(\"audio\", Audio(decode=True))\n",
        "\n",
        "samples = dataset[\"train\"].select(range(10))  # first 10\n",
        "\n",
        "target_sr = 16000\n",
        "\n",
        "all_refs = []\n",
        "all_preds = []\n",
        "\n",
        "for i, sample in enumerate(samples):\n",
        "    print(f\"\\n========== AUDIO CLIP {i+1} (Whisper) ==========\")\n",
        "\n",
        "    # Load and preprocess audio\n",
        "    audio_array = sample[\"audio\"][\"array\"]\n",
        "    sr = sample[\"audio\"][\"sampling_rate\"]\n",
        "\n",
        "    # Mono\n",
        "    if audio_array.ndim > 1:\n",
        "        audio_array = np.mean(audio_array, axis=1)\n",
        "\n",
        "    # Resample to 16kHz\n",
        "    if sr != target_sr:\n",
        "        audio_array = librosa.resample(audio_array, orig_sr=sr, target_sr=target_sr)\n",
        "\n",
        "    # Normalize\n",
        "    audio_array = audio_array / np.max(np.abs(audio_array))\n",
        "\n",
        "    # Prepare inputs\n",
        "    inputs = whisper_processor(\n",
        "        audio_array,\n",
        "        sampling_rate=target_sr,\n",
        "        return_tensors=\"pt\"\n",
        "    ).input_features.to(device)  # audio features\n",
        "\n",
        "    # Generate tokens\n",
        "    with torch.no_grad():\n",
        "        predicted_ids = whisper_model.generate(inputs)\n",
        "\n",
        "    # Decode to text\n",
        "    transcription = whisper_processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "    # Store\n",
        "    all_refs.append(sample[\"text\"].lower().strip())\n",
        "    all_preds.append(transcription.lower().strip())\n",
        "\n",
        "    # Print\n",
        "    print(\"Ground Truth:\")\n",
        "    print(sample[\"text\"])\n",
        "    print(\"Whisper Prediction:\")\n",
        "    print(transcription)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_Uu8D53hn_L",
        "outputId": "caa57ed3-6b36-40b3-e90c-b6588fef1f7d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========== AUDIO CLIP 1 (Whisper) ==========\n",
            "Ground Truth:\n",
            " Hello there everyone and welcome back to GSL English. My name is Gideon and in today's lesson\n",
            "Whisper Prediction:\n",
            " Hello there everyone and welcome back to GSL English. My name is Gideon and in today's lesson\n",
            "\n",
            "========== AUDIO CLIP 2 (Whisper) ==========\n",
            "Ground Truth:\n",
            " we are going to study English together through a short story. So if you are new here let me just\n",
            "Whisper Prediction:\n",
            " We are going to study English together through a short story. So if you are new here, let me just\n",
            "\n",
            "========== AUDIO CLIP 3 (Whisper) ==========\n",
            "Ground Truth:\n",
            " very briefly explain how this lesson is going to work. So we are firstly going to read the story\n",
            "Whisper Prediction:\n",
            " very briefly explain how this lesson is going to work. So we are firstly going to read the story\n",
            "\n",
            "========== AUDIO CLIP 4 (Whisper) ==========\n",
            "Ground Truth:\n",
            " in its entirety okay and then we're just going to talk about it a little bit to make sure we\n",
            "Whisper Prediction:\n",
            " in its entirety. Okay. And then we're just going to talk about it a little bit to make sure we\n",
            "\n",
            "========== AUDIO CLIP 5 (Whisper) ==========\n",
            "Ground Truth:\n",
            " fully understood what was going on and then we are going to break it down\n",
            "Whisper Prediction:\n",
            " fully understood what was going on and then we are going to break it down\n",
            "\n",
            "========== AUDIO CLIP 6 (Whisper) ==========\n",
            "Ground Truth:\n",
            " paragraph by paragraph isolating different terms different expressions and\n",
            "Whisper Prediction:\n",
            " paragraph by paragraph isolating different terms different expressions\n",
            "\n",
            "========== AUDIO CLIP 7 (Whisper) ==========\n",
            "Ground Truth:\n",
            " vocabulary so you will most certainly come away from this lesson with\n",
            "Whisper Prediction:\n",
            " and vocabulary so you will most certainly come away from this lesson with\n",
            "\n",
            "========== AUDIO CLIP 8 (Whisper) ==========\n",
            "Ground Truth:\n",
            " something new but also you'll come away with an idea of how you can study\n",
            "Whisper Prediction:\n",
            " something new but also you'll come away with an idea of how you can study\n",
            "\n",
            "========== AUDIO CLIP 9 (Whisper) ==========\n",
            "Ground Truth:\n",
            " English so please before we get into it don't forget to subscribe to my channel\n",
            "Whisper Prediction:\n",
            " English. So please before we get into it don't forget to subscribe to my channel\n",
            "\n",
            "========== AUDIO CLIP 10 (Whisper) ==========\n",
            "Ground Truth:\n",
            " I post content every week to help you speak natural, fluent and confident English.\n",
            "Whisper Prediction:\n",
            " I post content every week to help you speak natural, fluent and confident English.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wer_score = wer(all_refs, all_preds)\n",
        "cer_score = cer(all_refs, all_preds)\n",
        "\n",
        "print(\"\\n========== WHISPER EVALUATION ==========\")\n",
        "print(f\"Total samples evaluated: {len(all_refs)}\")\n",
        "print(f\"Word Error Rate (WER): {wer_score:.3f}\")\n",
        "print(f\"Character Error Rate (CER): {cer_score:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-4g6YMaiCy0",
        "outputId": "09da6385-0fa5-4607-84c8-f592a688893e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========== WHISPER EVALUATION ==========\n",
            "Total samples evaluated: 10\n",
            "Word Error Rate (WER): 0.038\n",
            "Character Error Rate (CER): 0.015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation Summary â€“ Whisper Medium\n",
        "\n",
        "The Whisper-medium ASR model was evaluated on ten English podcast audio clips. The model achieved a Word Error Rate (WER) of 3.8% and a Character Error Rate (CER) of 1.5%, indicating high transcription accuracy.\n",
        "\n",
        "Compared to Wav2Vec2-base, Whisper demonstrated significantly better performance, particularly in handling conversational speech and contextual word prediction."
      ],
      "metadata": {
        "id": "rjd94wKWj3b4"
      }
    }
  ]
}