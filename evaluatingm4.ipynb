{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation of Hubert Large ASR model\n",
        "\n",
        "This notebook evaluates the **Hubert Large ASR model** automatic speech recognition (ASR) model on the **GSL English Podcast Dataset** from **Hugging Face**. The objective is to analyze how accurately the model transcribes short English speech clips.\n",
        "\n",
        "The audio samples are preprocessed and passed through the pretrained **Hubert Large ASR ** model to generate transcriptions. Model performance is measured using standard ASR evaluation metrics:\n",
        "\n",
        "- **Word Error Rate (WER)**\n",
        "- **Character Error Rate (CER)**"
      ],
      "metadata": {
        "id": "D8dS_SJ4uBZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torchaudio librosa soundfile --quiet"
      ],
      "metadata": {
        "id": "_LxM0kbguCkX"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchcodec --quiet"
      ],
      "metadata": {
        "id": "dsihWOQmuEzn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jiwer --quiet"
      ],
      "metadata": {
        "id": "019hDdgWuH0z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import librosa\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from transformers import HubertForCTC, Wav2Vec2Processor\n",
        "from jiwer import wer, cer"
      ],
      "metadata": {
        "id": "ENsaEt34uJ_3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"vietnhat/gsl-english-podcast-dataset\")\n",
        "samples = dataset[\"train\"].select(range(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CA0xRXGjuNNO",
        "outputId": "5a5c583a-a05c-4e40-cf52-a7eb568a46e5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processor = Wav2Vec2Processor.from_pretrained(\"facebook/hubert-large-ls960-ft\")\n",
        "model = HubertForCTC.from_pretrained(\"facebook/hubert-large-ls960-ft\").to(\"cuda\")"
      ],
      "metadata": {
        "id": "PXE5Qv6zuc9Q"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_sr = 16000\n",
        "\n",
        "predictions = []\n",
        "references = []\n",
        "\n",
        "for i, sample in enumerate(samples):\n",
        "    print(f\"\\n========== AUDIO CLIP {i+1} ==========\")\n",
        "\n",
        "    audio = sample[\"audio\"][\"array\"]\n",
        "    sr = sample[\"audio\"][\"sampling_rate\"]\n",
        "\n",
        "    if audio.ndim > 1:\n",
        "        audio = np.mean(audio, axis=1)\n",
        "\n",
        "    if sr != target_sr:\n",
        "        audio = librosa.resample(audio, orig_sr=sr, target_sr=target_sr)\n",
        "\n",
        "    audio = audio / np.max(np.abs(audio))\n",
        "\n",
        "    inputs = processor(audio, sampling_rate=target_sr, return_tensors=\"pt\", padding=True)\n",
        "    input_values = inputs.input_values.to(\"cuda\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_values).logits\n",
        "\n",
        "    predicted_ids = torch.argmax(logits, dim=-1)\n",
        "    transcription = processor.decode(predicted_ids[0])\n",
        "\n",
        "    print(\"Ground Truth:\")\n",
        "    print(sample[\"text\"])\n",
        "    print(\"Prediction:\")\n",
        "    print(transcription.lower())\n",
        "\n",
        "    predictions.append(transcription.lower())\n",
        "    references.append(sample[\"text\"].lower())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUi43dbQuiEp",
        "outputId": "d644eb61-8c90-48d5-d058-c6ee6280be45"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========== AUDIO CLIP 1 ==========\n",
            "Ground Truth:\n",
            " Hello there everyone and welcome back to GSL English. My name is Gideon and in today's lesson\n",
            "Prediction:\n",
            "hello there every one and welcome back to g s el english my name is gideon and in to day's lesson\n",
            "\n",
            "========== AUDIO CLIP 2 ==========\n",
            "Ground Truth:\n",
            " we are going to study English together through a short story. So if you are new here let me just\n",
            "Prediction:\n",
            "we are going to study english together through a short story so if you are new here let me just\n",
            "\n",
            "========== AUDIO CLIP 3 ==========\n",
            "Ground Truth:\n",
            " very briefly explain how this lesson is going to work. So we are firstly going to read the story\n",
            "Prediction:\n",
            "very briefly explain how this lesson is going to work so we are firstly going to read the story\n",
            "\n",
            "========== AUDIO CLIP 4 ==========\n",
            "Ground Truth:\n",
            " in its entirety okay and then we're just going to talk about it a little bit to make sure we\n",
            "Prediction:\n",
            "in its entirety o k and then we're just going to talk about it a little bit to make sure we've\n",
            "\n",
            "========== AUDIO CLIP 5 ==========\n",
            "Ground Truth:\n",
            " fully understood what was going on and then we are going to break it down\n",
            "Prediction:\n",
            "fully understood what was going on and then we are going to break it down\n",
            "\n",
            "========== AUDIO CLIP 6 ==========\n",
            "Ground Truth:\n",
            " paragraph by paragraph isolating different terms different expressions and\n",
            "Prediction:\n",
            "paragraph by paragraph isolating different terms different expressions\n",
            "\n",
            "========== AUDIO CLIP 7 ==========\n",
            "Ground Truth:\n",
            " vocabulary so you will most certainly come away from this lesson with\n",
            "Prediction:\n",
            "and vocabulary so you will most certainly come away from this lesson with\n",
            "\n",
            "========== AUDIO CLIP 8 ==========\n",
            "Ground Truth:\n",
            " something new but also you'll come away with an idea of how you can study\n",
            "Prediction:\n",
            "something new but also you'll come away with an idea of how you can study\n",
            "\n",
            "========== AUDIO CLIP 9 ==========\n",
            "Ground Truth:\n",
            " English so please before we get into it don't forget to subscribe to my channel\n",
            "Prediction:\n",
            "dy english so please before we get into it don't forget to subscribe to my channel\n",
            "\n",
            "========== AUDIO CLIP 10 ==========\n",
            "Ground Truth:\n",
            " I post content every week to help you speak natural, fluent and confident English.\n",
            "Prediction:\n",
            "i post content every week to help you speak natural fluent and confident english\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_wer = wer(references, predictions)\n",
        "final_cer = cer(references, predictions)\n",
        "\n",
        "print(\"\\n========== FINAL EVALUATION ==========\")\n",
        "print(\"Total samples evaluated:\", len(samples))\n",
        "print(\"Word Error Rate (WER): {:.3f}\".format(final_wer))\n",
        "print(\"Character Error Rate (CER): {:.3f}\".format(final_cer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZDc0qWzv1al",
        "outputId": "e5e576f3-92b7-4a57-b39e-d7feb989c5ee"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========== FINAL EVALUATION ==========\n",
            "Total samples evaluated: 10\n",
            "Word Error Rate (WER): 0.115\n",
            "Character Error Rate (CER): 0.033\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation Summary â€“ Hubert Large ASR\n",
        "\n",
        "The Hubert-large ASR model was evaluated on ten English podcast audio clips. It achieved a Word Error Rate (WER) of 11.5% and a Character Error Rate (CER) of 3.3%, indicating good transcription accuracy, though slightly behind Whisper-medium in this dataset."
      ],
      "metadata": {
        "id": "Wd_BAexHwGk3"
      }
    }
  ]
}